{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f17f245-9526-4bd9-96f2-7c2810b121c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.video import r2plus1d_18, R2Plus1D_18_Weights\n",
    "from torchvision.models.video import mvit_v2_s, MViT_V2_S_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.io import read_video\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca273ed5-d3a0-4864-b3f6-43b5f389c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "DATA_DIR = './eyeVideos'\n",
    "CSV_FILE = './video_labels.csv'\n",
    "\n",
    "# Load labels from CSV\n",
    "labels_df = pd.read_csv(CSV_FILE)\n",
    "labels_dict = {row['filename']: row['label'] for _, row in labels_df.iterrows()}\n",
    "\n",
    "# Custom Video Dataset\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, labels_dict, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform = transform\n",
    "        self.video_paths = list(labels_dict.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_name = self.video_paths[idx]\n",
    "        video_path = os.path.join(self.root_dir, video_name)\n",
    "        video, _, _ = read_video(video_path, pts_unit='sec')  # Load full video\n",
    "\n",
    "        video = self.random_selection(video)\n",
    "\n",
    "        video = video.permute(3, 0, 1, 2)  # Convert (Frames, H, W, C) → (C, Frames, H, W)\n",
    "        video = video.float() / 255.0  # Normalize\n",
    "\n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "\n",
    "        label = self.labels_dict[video_name]\n",
    "        return video, label\n",
    "\n",
    "    @staticmethod\n",
    "    def random_selection(video, num_frames=100, interval=1):    # shape: (Frames, H, W, C)\n",
    "        video_length = video.shape[0]\n",
    "        starting_frame = np.random.randint(0, video_length-num_frames*interval)\n",
    "        return video[starting_frame:starting_frame+num_frames*interval:interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3cb0ff9-92e0-4142-ac4e-c3098aab2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 100, 256, 256]), 2, 'hypo_1_163.mp4')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load one sample from the dataset\n",
    "dataset = VideoDataset(DATA_DIR, labels_dict)\n",
    "\n",
    "# Get the first video and label\n",
    "video_sample, label = dataset[0]\n",
    "\n",
    "# Print video shape and label\n",
    "video_shape = video_sample.shape  # (C, Frames, H, W)\n",
    "video_filename = dataset.video_paths[0]\n",
    "\n",
    "video_shape, label, video_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a70877-f7e7-4fb5-b5f8-3db38c4a94b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing fc.weight from checkpoint due to shape mismatch.\n",
      "Removing fc.bias from checkpoint due to shape mismatch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 68/252 [02:57<07:03,  2.30s/it, running_loss=1.06] "
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load Dataset\n",
    "dataset = VideoDataset(DATA_DIR, labels_dict, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Load R(2+1)D model\n",
    "    # Jooyoung's way:\n",
    "    # weights = R2Plus1D_18_Weights.DEFAULT\n",
    "    # model = r2plus1d_18(weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "# Offline loading:\n",
    "def load_model_offline(model_name, pth_path, ignore_key):\n",
    "    model = model_name(weights=None, num_classes=3)\n",
    "    state_dict = torch.load(pth_path, weights_only=True)\n",
    "    # Remove parameters from the head if they exist in the state dict\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith(ignore_key):\n",
    "            print(f\"Removing {key} from checkpoint due to shape mismatch.\")\n",
    "            del state_dict[key]\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    return model\n",
    "model = load_model_offline(r2plus1d_18, \"./pretrained_weights/r2plus1d_18-91a641e6.pth\", ignore_key=\"fc\")\n",
    "# model = load_model_offline(mvit_v2_s,\"./pretrained_weights/mvit_v2_s-ae3be16 7.pth\", ignore_key=\"head\")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "training_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, total=len(train_loader))\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        training_loss.append(loss.item())\n",
    "        pbar.set_postfix(dict(running_loss=loss.item()))\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694688a-5299-4ef3-b32a-b1652a98377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(inputs)  # Raw logits\n",
    "        probs = F.softmax(outputs, dim=1)  # Convert to probabilities\n",
    "        preds = torch.argmax(probs, dim=1)  # Get predicted class\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Compute AUROC & AUPRC for each class\n",
    "num_classes = 3\n",
    "auroc_scores = []\n",
    "auprc_scores = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    y_true = (all_labels == i).astype(int)  # Convert to binary labels\n",
    "    y_score = all_probs[:, i]  # Probability of class i\n",
    "    \n",
    "    auroc = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "\n",
    "    auroc_scores.append(auroc)\n",
    "    auprc_scores.append(auprc)\n",
    "\n",
    "    print(f\"Class {i} - AUROC: {auroc:.4f}, AUPRC: {auprc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac802aac-3f3b-4bb9-ab70-f5c6d5ef7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and Plot Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"normal\", \"hyper\", \"hypo\"], yticklabels=[\"normal\", \"hyper\", \"hypo\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4427e8-8250-46f8-b417-4132e6b45d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "CLASS_NAMES = {'normal': 0, 'hyper': 1, 'hypo': 2}\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2c476-60d4-4815-960d-9ccdbf90abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"video_classification_model.pth\"  # Choose a filename\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1eddd-f91e-4be3-9998-1eaf04436291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert data to Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"true_label\": all_labels,\n",
    "    \"predicted_label\": all_preds\n",
    "})\n",
    "\n",
    "# Add probability columns for each class\n",
    "num_classes = all_probs[0].shape[0]\n",
    "for i in range(num_classes):\n",
    "    df[f\"prob_class_{i}\"] = [prob[i] for prob in all_probs]\n",
    "\n",
    "# Save as CSV\n",
    "csv_filename = \"predictions.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
